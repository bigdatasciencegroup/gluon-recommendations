{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code in part inspired by: https://github.com/EthanRosenthal/torchmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, ndarray\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/tmp/ml-100k/'\n",
    "prefix='ml-100k'\n",
    "num_emb = 64\n",
    "opt = 'Adam'\n",
    "lr = 0.02\n",
    "mmntm = 0.\n",
    "wd = 0.\n",
    "batch_size = 50\n",
    "ctx = mx.gpu()\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip /tmp/ml-100k/ml-100k.zip -d /tmp/ml-100k/\n"
     ]
    }
   ],
   "source": [
    "def download_ml_data(prefix, os_path):\n",
    "    if not os.path.exists(os_path+\"%s.zip\" % prefix):\n",
    "        print(\"Downloading MovieLens data: %s\" % prefix)\n",
    "        os.system(\"wget http://files.grouplens.org/datasets/movielens/{}.zip -P {}\".format(prefix, data_path))\n",
    "    print(\"unzip {}{}.zip -d {}\".format(data_path,prefix, data_path))\n",
    "    os.system(\"unzip {}{}.zip -d {}\".format(data_path,prefix, data_path))   \n",
    "\n",
    "\n",
    "download_ml_data(prefix=prefix, os_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 1683)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_id(fname):\n",
    "    mu = 0\n",
    "    mi = 0\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            tks = line.strip().split('\\t')\n",
    "            if len(tks) != 4:\n",
    "                continue\n",
    "            mu = max(mu, int(tks[0]))\n",
    "            mi = max(mi, int(tks[1]))\n",
    "    return mu + 1, mi + 1\n",
    "max_users, max_items = max_id(data_path + prefix  +'/u.data')\n",
    "(max_users, max_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path + prefix + '/u1.base', header=None, sep='\\t')\n",
    "test_df = pd.read_csv(data_path + prefix + '/u1.test', header=None, sep='\\t')\n",
    "\n",
    "train_data = nd.array(train_df[[0,1]].values, dtype=np.float32)\n",
    "train_label = nd.array(train_df[2].values, dtype=np.float32)\n",
    "\n",
    "test_data = nd.array(test_df[[0,1]].values, dtype=np.float32)\n",
    "test_label = nd.array(test_df[2].values, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMatrixDataset(gluon.data.Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        assert data.shape[0] == len(label)\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        if isinstance(label, ndarray.NDArray) and len(label.shape) == 1:\n",
    "            self._label = label.asnumpy()\n",
    "        else:\n",
    "            self._label = label       \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx, 0], self.data[idx, 1], self.label[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFBlock(gluon.Block):\n",
    "    def __init__(self, max_users, max_items, num_emb, dropout_p=0.5):\n",
    "        super(MFBlock, self).__init__()\n",
    "        \n",
    "        self.max_users = max_users\n",
    "        self.max_items = max_items\n",
    "        self.dropout_p = dropout_p\n",
    "        self.num_emb = num_emb\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.user_embeddings = gluon.nn.Embedding(max_users, num_emb)\n",
    "            self.item_embeddings = gluon.nn.Embedding(max_items, num_emb)\n",
    "            self.dropout = gluon.nn.Dropout(dropout_p)\n",
    "            self.dense = gluon.nn.Dense(num_emb, activation='relu')\n",
    "            \n",
    "    def forward(self, users, items):\n",
    "        a = self.user_embeddings(users)\n",
    "        a = self.dense(a)\n",
    "        \n",
    "        b = self.item_embeddings(items)\n",
    "        b = self.dense(b)\n",
    "\n",
    "        predictions = self.dropout(a) * self.dropout(b)      \n",
    "        predictions = nd.sum(predictions, axis=1)\n",
    "        return predictions\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mfblock1_ (\n",
       "  Parameter mfblock1_embedding0_weight (shape=(944, 64), dtype=float32)\n",
       "  Parameter mfblock1_embedding1_weight (shape=(1683, 64), dtype=float32)\n",
       "  Parameter mfblock1_dense0_weight (shape=(64, 0), dtype=float32)\n",
       "  Parameter mfblock1_dense0_bias (shape=(64,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MFBlock(max_users=max_users, max_items=max_items, num_emb=num_emb, dropout_p=0.)\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = gluon.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx, force_reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd',\n",
    "                        {'learning_rate': lr, 'wd': wd, 'momentum': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = gluon.data.DataLoader(SparseMatrixDataset(train_data, train_label), \n",
    "                                        shuffle=True, batch_size=batch_size)\n",
    "test_data_iter = gluon.data.DataLoader(SparseMatrixDataset(test_data, test_label),\n",
    "                                          shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(data, net):\n",
    "    acc = mx.metric.RMSE()\n",
    "    for i, (user, item, label) in enumerate(data):\n",
    "        user = user.as_in_context(ctx).reshape((batch_size,))\n",
    "        item = item.as_in_context(ctx).reshape((batch_size,))\n",
    "        label = label.as_in_context(ctx).reshape((batch_size,))\n",
    "        predictions = net(user, item)\n",
    "        loss = loss_function(predictions, label)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.708269029855728"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_net(test_data_iter, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "#smoothing_constant = 10\n",
    "\n",
    "def train(data_iter, net):\n",
    "    for e in range(epochs):\n",
    "        print(\"epoch: {}\".format(e))\n",
    "        for i, (user, item, label) in enumerate(train_data_iter):\n",
    "            user = user.as_in_context(ctx).reshape((batch_size,))\n",
    "            item = item.as_in_context(ctx).reshape((batch_size,))\n",
    "            label = label.as_in_context(ctx).reshape((batch_size,))\n",
    "            with mx.autograd.record():\n",
    "                output = net(user, item)               \n",
    "                loss = loss_function(output, label)\n",
    "                loss.backward()\n",
    "            net.collect_params().values()\n",
    "            trainer.step(batch_size)\n",
    "        print(\"EPOCH {}: RMSE ON TRAINING and TEST: {}. {}\".format(e,\n",
    "                                                                   eval_net(train_data_iter, net),\n",
    "                                                                   eval_net(test_data_iter, net)))\n",
    "    return \"end of training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "EPOCH 0: RMSE ON TRAINING and TEST: 0.9558644323796034. 0.994868129491806\n",
      "epoch: 1\n",
      "EPOCH 1: RMSE ON TRAINING and TEST: 0.9496117281913757. 0.9851171465218067\n",
      "epoch: 2\n"
     ]
    }
   ],
   "source": [
    "train(train_data_iter, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential6_ (\n",
       "  Parameter sequential6_embedding0_weight (shape=(944, 64), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential6_dense0_weight (shape=(64, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential6_dense0_bias (shape=(64,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = gluon.nn.Sequential()\n",
    "with net1.name_scope():\n",
    "    net1.add(gluon.nn.Embedding(max_users, num_emb))\n",
    "    net1.add(gluon.nn.Dense(64))\n",
    "    \n",
    "net1.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path+'u1.base', header=None, sep='\\t')\n",
    "test_df = pd.read_csv(data_path+'u1.test', header=None, sep='\\t')\n",
    "\n",
    "user_train_data = nd.array(train_df[[0]].values, dtype=np.float32)\n",
    "item_train_data = nd.array(train_df[[1]].values, dtype=np.float32)\n",
    "train_label = nd.array(train_df[2].values, dtype=np.float32)\n",
    "\n",
    "user_test_data = nd.array(test_df[[0]].values, dtype=np.float32)\n",
    "item_test_data = nd.array(test_df[[1]].values, dtype=np.float32)\n",
    "test_label = nd.array(test_df[2].values, dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_data_iter = gluon.data.DataLoader(gluon.data.ArrayDataset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
